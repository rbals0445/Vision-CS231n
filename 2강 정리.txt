Image classification 이란?
이미지를 픽셀들의 배열로 표현하고 거기에 label을 할당하는 작업.

이미지 분류 파이프라인

Input -> learning -> Evaluation 

Input : N개의 이미지 set이 있고 label된 K개의 각각 다른 클래스(카테고리 존재)
이 데이터를 training set으로 활용한다

Learning : 모든 클래스들이 어떻게 생겼는지 training set을 사용해서 학습시킨다.
learning a model or training a classifier 라고 부른다.

Evaluation : label이 뭔지 predict 시켜봄으로써  classifier의 성능을 테스트한다.
참고로 테스트할때는 새로운 set의 이미지를 사용한다(처음보는걸로)
결과가 나오면 예측한거랑 실제이미지를 비교해본다.
ground thruth(실측 자료) 라는 표현을 쓰는데 이것은 classifier랑 비교할 대조본(원본) 을 말한다.

Nearest Neighbor Classifier (최근접 이웃 분류기)
CNN과는 관련이 없고 매우 드물게 사용된다.

그럼 왜 쓰는가?
이미지 분류 문제에 대해서 가장 기본적 접근을 하는 idea를 제공하기 때문이다.

dataset은 CIFAR-10 이라는걸 사용한다. (최종 결과값이 10자리로 나와서 -10인것 같기도)
32*32 pixel의 10개 클래스들이 존재하고 수많은 이미지들이 있다.

training set 5만장, test set 1만장이 있다.

L1 distance ( Manhattan distance)
array화 된 원소들의 픽셀값의 차이의 절댓값 을 모두 더한다.
두개가 같거나 작을수록 0이나 0에 가까울것이고 차이가 클수록 합도 커질것이다.

L2 distance ( euclidean distance)
두 벡터의 차를 제곱한 후 다 더해서 루트를 씌움.


L1 vs L2
L1 : 두 벡터간의 차이가 큰것들
L2 : 두 벡터간의 차이가 미미한것들

L2가 좀 더 벡터의 차이에 크게 반응한다.(unforgiving)
즉 두 벡터간의 차이가 크면 L2보다는 L1을 쓰는것이 좀 더 좋다는 뜻이다.
L2는 여러가지 벡터의 차이가 미미한 경우에 사용하는것이 좋다.

또한 L1,L2 norm은 p-norm 중에 가장 많이 쓰이는 norm이다. https://planetmath.org/vectorpnorm 
여길 참고해도 좋고, 선형대수 저번에 정리한것에 그대로 있다. 좀 더 알아보기 쉬움.

k-Nearest Neighbor Classifier (kNN 분류기)
아이디어는 매우 간단하다 .
training set의 가장 근접한(가까운) 단일 이미지를 찾는것 대신에 top k개의 근접한 이미지를 찾는다. 
그다음 test 이미지에 vote를 한다. k=1 일땐 NN과 똑같다고 보면 된다. (최상위 1개만 쓸거니까)

최상위 이미지가 우연찮게 픽셀값이 비슷해서 이상한게 잡혔다고 쳐보자.
NN을 사용하면 이상한걸 prediction 할것이다.
하지만 k값을 높여줄수록 좀 더 outlier을 제거하는데 좀 더 효율적일것이다. (즉 맞을 확률이 조금이라도 더 높아질 수 있다.)

*outlier : 비정상적으로 벗어난것들. IQ 평균이 50이라고 가정하면 어떤사람만 300일때 그런사람을 걸러야 평균이 좀더 정확해짐.

여기에 색깔이 입혀진 지역은 L2 distance를 사용한 분류기로 만든 decision boundaries(결정 경계) 이다.
하얀색 지역은 모호하게 분류된 경우이다. (예를들면 적어도 2개 이상의 클래스들이 투표수가 같을경우)
NN에는 흰색 경계가 나올 수 없는 이유이기도 하다.

NN을 보면 outlier를 처리하지 못해서 초록색 안에 파란색 섬(island)이 있기도 하고.. 이런것들이 incorrect prediction을 하게 만든다.
반면에 k=5 인 KNN은 이러한 irregularities(outlier들이라고 보면 될 것 같다.) 들이 생기지 않게 좀 더 부드럽게한다.
여기 사진엔 나오지 않지만 test data를 좀 더 일반화 할 수 있다.

5-NN 분류기를 보면 회색부분은 위에서 설명한것 처럼 2개 이상의 색이 같은 표를 받은것이다.
예를들면 2표 red, 2표 blue, 1표 green 이런식.

실제로 kNN을 쓰는게 거의 무조건 좋은것 같다는걸 눈으로 확인했다.
그러나 k를 몇으로 하는게 좋은가? 무조건 k가 높으면 좋은게 아닐까? K를 어떻게 설정할지에 대해서 배워본다.

Hyperparameter 튜닝을 위한 Validation Sets(검증 셋)

kNN은 최적의 k를 요구한다. 하지만 L1 norm, L2 norm 말고도 여러가지 distance function이 존재한다. 또한 내적 등등 여러가지 방법이 있다.

이러한 선택들을 Hyperparameter라고 부른다.그리고 이것들은 data로부터 배워진(학습된) 많은 머신러닝 알고리즘에서 나타난다.
어떤 값을 선택해서 세팅할지는 항상 명확하지 않다.

가장 쉬운 방법은 그냥 여러값들을 넣어서 시도해보고 그 결과를 토대로 선택하는 것이다.
좋은 아이디어이고 실제로 그렇게 할 것이지만 매우 조심히 해야한다고 한다. 왜??

중요! 특히 hyperparameter를 수정할 목적으로 테스트셋을 사용해선 안된다.
(원칙상 or 이론상 ideally)ML 알고리즘을 만들때 test set을 알고리즘 테스트때 딱 한번 외에는 손대서는 안될 정말 소중한 자원으로 생각해야한다. 그렇지 않으면 테스트 셋에 맞추기 위해서 hyperparameter를 수정하는 위험이 있다. 그렇게 하면 실제 모델을 배치했을때 상당한 성능 감소가 나올 수 있다.
-> 테스트셋에서만 굴러가는게 아니고 범용적인걸 고려해야 함.

테스트셋에다가 hyperparameter를 맞추는걸 test set에 overfit 했다고 한다.
다른 관점으로 보면 오히려 test set을 training set처럼 효과적으로 사용했다. 따라서 실제로 모델을 배치했을때 나올 값보다는 너무 optimistic 한 결과가 나올것이다.
-> 좀만 생각해보면 당연하다.. 왜냐? 기출문제를 미리 풀어서 시험을 보면 당연 점수가 잘나온다. 하지만 그 기출문제만 풀 줄 안다면?
다음 시험부터는 어떻게 될것인가.. 당연히 점수가 이전보다 낮게 나올 수 밖에 없다.(일반적으로)

그러나 평가하는 마지막에만 test set을 사용하면 우리가 만든 분류기의 일반화된 성능을 잘 평가하는 척도(proxy)가 될 것이다.

운좋게도 test set을 건들지 않고 올바르게 hyperparameter를 튜닝하는 법이 있다.
그 방법은 우리의 training set을 2개로 나누는 것이다.
1. 미세하게 더 작은 트레이닝 셋 우리는 이것을 (validation set) 이라고 부른다. 한국말로 검증 셋

ex) 5만개의 CIFAR-10 을 예시로 들어보면
49000장은 training set으로 쓰고 1000장은 validation set으로 사용한다.

validation set은 hyper-parameters를 튜닝하기 위한 가짜 test set으로 사용한다.(필수적)

Cross-validation (교차 검증)

training data의 사이즈가 작을경우에는 '교차검증' 이라고 불리는 좀 더 정교한 튜닝 기술을 사용한다
여러가지 validation set을 테스트 한 후 평균적인 성능을 내서 어떤 k가 더 좋고 noise가 적은 결과를 낼지 예측하는것이다.


예를들어 5-fold cross-validation 을 예시로 들면 (5개의 그룹으로 이루어진 교차검증 으로 생각하면 될 것 같다)
training data를 같은 크기의 5개의 folds로 나누고 4개는 training, 1개는 validation 으로 사용한다.
어떤 validation fold를 사용할지에 따라 iterate 하고 성능을 평가하고 다른 fold에 대해서 성능의 평균을 낸다.

<!-- 이해가 잘 안감-->
이 사진은
각각의 k에 대해서 4개의 folds로 트레이닝을 시키고 5번째 fold로 성능을 평가한다.
('A',B,C,D,E), (A,'B',C,D,E) , (A,B,'C',D,E) .. 총 5개 따라서 5개의 accuracy 가 나옴. (n^2 반복)
각 k마다 검증셋으로 활용한 그룹들에서 5개의 정확도가 나온다.
정확도는 y축, 결과는 점이다.
error bar는 표준편차를 나타낸다.
k = 7 일때 제일 높은 accuracy를 가진다.

fold를 올릴수록 좀더 부드러운 곡선(noise가 적은)을 볼 수 있을것이다.
<!-- -->
k-fold cross validation(K 분할 교차 검증)
실제로 사람들은 교차검증을 피하고 하나의 validation set만 가지는걸 선호한다.
왜냐하면 교차검증은 cost가 너무 비싸다(계산할게 많음. 데이터 1억개면 1억개의 제곱이라고 생각하면 됨.)

사람들은 50~90% 정도를 training으로 쓰고 나머지를 validation으로 쓰는 경향이 있다.
그러나 이 %는 여러가지 요인에 의존적이다.(제한이 있다)
만약 hyperparameter가 너무 크면 좀더 큰 validation split을 선호할 것이다. (training set을 줄인다는 말인것 같음)
만약 validation set이 너무 적으면(수백개) 교차검증을 사용하는것이 더 안전하다.
실제로 볼 수 있는 일반적인 개수의 folds는 3개,5개,10개 정도 이다.

Nearest Neighbor classifier의 장,단점

장점 : 구현하고 이해하기 쉽다. training에 시간이 들지 않는다.O(1) (그냥 저장하고 인덱스 매김)
단점 : test time에 드는 연산 cost가 있다. test image하나를 training data 전체랑 비교해야하기 때문에.
실 사용에서는 training time보다 test time의 효율성에 좀 더 주의한다. ( test time이 더 적게 들어야한다. training time은 그렇게 신경 x)
deep neural network는 NN과는 완전 반대이다. training time이 굉장히 길고 test time이 굉장히 짧다.
이런 방식이 실제에서는 좀 더 바람직한 방법이다.

NN classifier의 연산량은 아직도 연구가 되는 주제이다.
ANN (Approximate Nearest Neighbor) 근사 최근접 이웃 알고리즘 이나 라이브러리들이 있어서 이것이 dataset 내에서 NN을 찾는것을 가속화해준다. 
이러한 알고리즘들은 정확도를 조금 잃는대신에 시/공간 복잡도를 크게 이득 볼 수 있다.(NN 검색시에)
kdtree 를 만들거나 k-means 알고리즘을 실행할때 사용하는 전처리 stage에 의존하는 편이다.
* 나는 kdtree와 k-means 알고리즘이 뭔지 모른다.
(다음번에 또 볼때엔 이 부분도 찾아봐야겠다)

최근접 이웃 분류기는 '차원이 낮은 data' 에서 좋은 선택이 될 수 있다.
하지만 거의 실생활 이미지 분류에서는 쓰일 일이 없다.

실제로는 고차원 물체라서 픽셀들도 많고, 고차원에서의 distance는 매우 직관적이지 않다.
아래 사진을 픽셀 기반 L2유사도로 보면 눈으로 보는것곽 매우 많이 다르다.

아래 사진은 원본을 1로 잡고 2,3,4번 사진들이 L2 distance 기준으로 다 같은 거리만큼 떨어져 있다.
(즉 sum이 모두 같다는 말이다)
근데 어떻게 2,3,4가 같은 사진인가.. 눈으로 보기에 다른게 보이는데..
이 예시를 통해서 pixel로 구한 distance는 지각적(perceptual)으로나 의미적으로나 맞지 않다.

픽셀 기반 차이는 부적절한걸 보여주는 다른 예시이다. 아래 사진은 t-SNE 시각화 기법을 사용해서 보여주는 예시이다.
* t-SNE는
https://lvdmaaten.github.io/tsne/
여길 참고하면 되는데 
고차원 dataset의 차원을 축소해주는 기술이라고 나와있다.
위에 CIFAR-10 예시를 2차원 으로 임베딩 해서 보여주는것이다.
근처에 있을수록 L2거리가 굉장히 가깝다.(유사하다)
조금 확대해서 보면 배경이 비슷한 비행기와 트럭이 같이 묶이는등.. 실제 내용의 차이보다는 배경에 많은 영향을 받는걸 볼 수 있다.

가까이 있는 이미지들은 보편적 색깔의 분포나 배경색에 영향을 많이 받는다. 그들의 실제 의미와는 관계없이 (개나 고양이 같은 종류)
그러면 이런 배경이나, 다른 종 에 관계없이 알맞게 clustering 을 이루게 하려면 pixel 을 넘어선 다른 것들이 필요하다.



=====================================
Linear classification (선형 분류)
왜 Linear일까 생각해봤는데 가장 직관적인 이유는 함수가 1차함수이다. 그래서 선형인것 같다는 느낌을 받았다.
또한 쭉 보면 알지만 img들의 평균으로 딱 하나의 template만 있다.

지난번에 봤던 kNN 분류기는 단점이 많았다.
1. training data를 배열같은데에 저장하는데 공간 효율성이 떨어진다. (보통 기가바이트단위임)
2. 모든 training data와 비교를 하기때문에 연산량이 너무 많다.

지금부터 자연스럽게 전체 NN이나(Neural Network) CNN으로 확장할 수 있는 더 강력한 이미지 분류 접근법을 배워볼것이다.
이 접근법은 2개의 주요 요소들이 있다.

score 함수와, 손실함수(loss function) 이 있다.
raw data에 class score를 map하는 함수, 예상점수와 실측 label 사이의 차이를 정량화 하는 함수.(차이를 나타내는 함수)

score 함수의 매개변수에 대한 손실함수를 최소화하는 최적화문제로 이어질것이다.

이미지에서 label score로의 파라미터화된 매핑
이 접근의 첫번째 요소는 score function을 정의하는것입니다.
각 클래스에대해서 이미지의 픽셀값들을 신뢰값(confidence score)로 매핑시키는것입니다.

f(x,b) = Wx + b 로 나타낼 수 있는데
각각의 변수에 대해서 설명을 하자면
x = img의 pixel들을 쭉 길게 늘려서 거대한 column 을 만드는 것이다. [ pixel x 1 ] 
b = bias vector (실제 이미지 값인 x와 상호작용이 없으면서 결과값에는 영향을 주는 값을 말한다)
W = weights(가중치) 인데 Wx + b의 값을 통해서 score가 나오게 되는데, 이때 matrix간의 연산이라서
그 최종 결과값에 맞추기 위한 행렬 이라고 보면 된다. 

ex) CIFAR-10 을 예시로 생각해보자.
32 x 32 x 3 = 3072 pixels 의 벡터를 길게 늘린다.
x = 3072 x 1 의 벡터가 된다. (실제 이미지)
score은 10개의 클래스에 대해서 결과값을 출력한다. 따라서
10 x 1 이 되어야한다.

행렬의 덧셈을 해보면 행과 열이 같아야한다는걸 알 수 있다.
따라서 b도 10 x 1이 되어야한다.

10 x 1 =  MAT x [ 3072 x 1 ] 이다.
MAT는 10 * 3072가 되어야 한다. 이 MAT가 W인것이다.
이때 W의 각 행은 각 class마다의 분류기가 된다.
그림으로 설명하면 쉬운데.. 좀만 생각해보면 결과값의 각 행이 class 의 점수이기 때문에
가중치의 각 행은 그 점수를 구하기 위한 분류기라고 생각하면 된다.
(사진 첨부) 

First, note that the single matrix multiplication Wxi is effectively evaluating 10 separate classifiers in parallel (one for each class), where each classifier is a row of W.

참고해야할것들 .
input data는 fixed 값이다. 하지만 parameter W와 b는 직접 수정할 수 있다.
우리의 목표는 우리가 계산한 값들이 training set의 실측값과 비슷한 score을 내는 W와 b를 설정하는것이다.
직관적으로 간단하게 말하자면 내가 분류한 data가 잘못 분류된 class보다는 점수가 높아야한다는 뜻이다.
(고양이 사진을 분류했는데 자동차 class에서 score가 더 높게나오면 안된다는뜻)

선형분류의 장점
1. training data를 W와 b를 설정하는데 학습할 자료로 사용한다. 그다음 W와 b가 설정되면
training set을 다 버리고 세팅된 w와 b를 이용해서 이미지의 픽셀을 넣고 계속 함수만 돌려서 score를 낸다.

이렇게 되면 kNN처럼 모든 training set과 비교하는 불필요한 연산들이 필요 없게 된다.
또한 이미지 분류가 간단한 행렬의 곱과 합으로만 이루어지기 때문에 전체 비교하는 kNN과 비교해서 굉장히 빠르다.

- 나중에 배울 CNN도 선형분류처럼 픽셀값을 score로 map 해주지만 매핑 함수(f)가 좀더 복잡하고 더 많은 parameter를 갖게된다.

선형분류 해석하기.

선형분류기는 클래스의 점수를 계산한다. 모든 3개의 컬러채널을 아우르는 픽셀값들의 가중치가 곱해진 합으로써 
이 W들에 어떤 값(음수 또는 양수)을 설정하느냐에 따라서 함수는  이미지의 특정 위치에서의 특정 컬러를 like or dislike 할 능력이 있따.

ship class를 예시로 들면, image의 주변에 blue가 많으면 좀 더 ship일 확률이 높다고 생각할것이다.(blue가 물의 색이랑 비슷하니까)
우리는 ship 분류기가 blue color channel에서 많은 가중치를 줄것이라고 생각할 수 있을것이다.(blue가 ship의 score을 올린다)
red,green color에서는 음의 가중치를 줌으로써  score를 낮춘다.

=====고양이 그림 예시====
image를 class score로 매핑한 예시를 보자. 
visualization을 위해서 4개의 pixel만 있다고 가정한것이다.(color channel도 고려하지 않았다. 간결성을 위해 단일 채널로 생각)
red는 cat, green은 dog고, blue는 ship이라고 가정하자.
여기 사진에 있는 빨 초 파 는 rgb color와는 상관이 없는것이다. 그냥 구분용임. 

아까 위에서 말했듯이 W의 행은 각 classifer를 나타낸다고 했다. 우린 cat을 빨강으로 보기로 했기때문에
빨강인것이다. 

이제 계산을 해보면 이 W의 assign은 좋지 않은것을 알 수 있다. 왜냐하면 cat score가 굉장히 낮게 나왔기 때문이다.
오히려 이건 cat을 dog처럼 보게 만드는 잘못된 W이다.

==이미지(고차원 점으로써)의 비유
이미지가 고차원 열벡터로 쭉 펴졌기 떄문에 (3072 * 1 같은것)
우리는 각 이미지를 3072(32*32*3 픽셀로 이루어진)차원 공간에서의 한 점 으로 해석할 수 있다.
마찬가지로 전체 dataset은 라벨링된 점들의 집합으로 볼 수 있다.

모든 클래스의 점수를 image의 픽셀들에 가중치를 곱한 합으로 정의했기 때문에
각각의 class score는 공간상에서 선형함수이다.(Wx + b꼴)
3072차원을 시각화할 수는 없기때문에 2차원으로 축소한다고 가정하면 우리의 classifier가 어떻게 작동하는지 시각화 할 수 있다.

==분류기 함수 예시-====
각각의 이미지는 한 point 를 나타낸다. 3개의 classifier가 나와있다.(비행기,차,사슴)
자동차 분류기를 예시로 들면(빨강) red line은 car class가 0점을 받은 모든 점들을 나타낸다.
red arrow는 증가 방향을 나타낸다. 그래서 빨간 선 오른쪽의 모든 점들은 positive score을 가지고 left는 음수 score를 가진다.

위에서 봤듯이 모든 W의 행은 분류기이다. 모든 클래스에 하나씩 대응하는.
이 숫자들을 기하학적으로 해석하면 우리가 W의 행을 하나를 바꾸면 (즉 어떤 클래스의 가중치를 바꾸면) 그에 상응하는 pixel 공간 line이 다른 방향으로 회전해버릴것이다. (기울기가 달라진다는 말 인것 같음)

b는 반면에 우리의 분류기가 line을 평행이동하게 해준다..
특히 bias terms 없이는 이미지의 픽셀이 0인것은 W에 관계없이 항상 score가 0점만 나오게 될것이다.
따라서 line은 강제로 origin(원점)을 지나게 될것이다.
( f라는 함수가 b가 있기때문에 함숫값이 0이더라도 위에 사진처럼 y값이 0이 아닌 지점들을 지나게 된 것이다.)

--> 그냥 함수적으로 봐도 Wx + b에서 w는 기울기고 b는 y값만 옮겨주는 평행이동 으로 보면 된다.

template matching으로써의 선형분류기 해석.
가중치 w에 대한 다른 해석으로는 W의 각 행이 각 클래스의 template에 해당한다.
각 클래스의 별로 한 이미지에 대한 점수는 내적을 사용해서 얻어진다.
이 내적은 각각의 template과 img를 이용해서 한다. 가장 잘 맞는 클래스를 찾기 위해서.

이걸 용어로 linear classifier가 template matching을 한다고 표현한다. template은 학습에 의해서 배워진다.
다르게 생각해보면 우리는 여전히 NN을 효과적으로 하고있다.(선형 분류기를 통해서) 그러나 수천개의 training img를 사용하기보다는 클래스당 1개의 이미지만 사용한다.(single image를 학습하고 반드시 template이 training set의 이미지중 하나가 될 필요는 없다)
거리함수로는 우리는 (내적한후 -)을 사용한다. L1, L2distance를 사용하는것 대신에.

====사진==
ship template은 파란 픽셀이 많다.
따라서 이 템플릿은 바다위에 떠있는 배 이미지와 내적을 할 때 높은 점수를 받을것이다.

게다가 참고로 말 template은 2개의 머리가 있다. dataset에서 왼쪽방향,오른쪽방향 으로 된 말들이 있었던 것이다.
linear classifier은 이 사진들을 merge해서 하나의 template으로 만든다.
비슷하게 자동차 또한 여러가지 사진들이 하나의 template으로 합쳐진것이다.


특히 이 템플릿은 빨강으로 끝난다. 이것은 dataset에 빨강 차들이 다른 색들의 차량보다 더 많았다는걸 의미한다.
linear classifer은 다양한 색을 가진 자동차들을 적절하게 분류하는데에는 어려움이 있다.(too weak)
하지만 나중에 신경망(NN)을 통해서 이것을 할 수 있을것이다.

Bias trick. 
다음으로 가기에 앞서 2개의 parameter(W,b)를 하나로 나타내는 트릭을 보자.
원래 식이 이랬다. = Wx+b

w,b 들을 각각 계속해서 추적하기에는 약간 어려움이 있다. 
가장 흔히 쓰이는 trick은 2개의 파라미터를 1개의 행렬로 합치는것이다.
x를 extend함으로써 추가적인 차원을 통해서  constant 1차원 (bias dimension)
이 추가 차원으로 새로운 score function이 단일 행렬 곱으로 좀 더 간소화 된다. (원래는 행렬곱 + 합이 필요했음)

즉 W에다가 b를 붙이고 x에는 상수 1 짜리 1차원을 더 더한다. (내적하면 어짜피 b를 따로 더한것과 같게됨.)

===
image data 처리. 
위에서는 이미지의 픽셀을 [0,255]로 나타냈다..
ML에서는 input 특징들을 일반화를 하는것은 매우 흔한일이다.(이미지의 각 픽셀은 각각의 특징으로 생각된다)
특히 모든 특징에서 평균을 빼서 데이터의 중심을 맞추는게 굉장히 중요합니다. (뭔말인지 잘 이해 안감)
image의 경우  training image의 평균을 계산하고, 그 평균을 모든 image에서 빼는것 을 말한다..(픽셀의 범위를[-127,127]로 얻기위해)
더 일반적인 전처리는 input feautre를 [-1,1]로 두는것이다
여기서 0은 중간에 온걸 의미하고 좀 더 중요하다. 하지만 이것을 정당화 하기 위해서는 좀 더 기다려야한다.
경사하강의 dynamics를 이해하기 전까지는...


추가적인 전처리는 각각의 특징


경사하강을 이해할때가지.


